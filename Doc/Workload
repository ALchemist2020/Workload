Workload Description 

Server Applications. For apache, we place multiple files on the server(e.g. 1.txt and 2.txt). We send a request from IP1 to access files 1.txt on the server and collect logs. All the high level apache log entries belong to the same request unit and all the corresponding audit logs should be attributed to the unit. We repeat this 10 times with different IP addresses and acquire the ground truth. In this process, we use a network record and replay tool GoPlay to record network traffic for each IP. Then we replay the traffic from different IPs at the same time, causing interleaving. Other server applications like nginx, proftpd and tightvnc follow a similar procedure.

Chromium. For chromium, we use HTTrack to crawl 10 popular websites, e.g.,yahoo.com and CNN.com, and all the content pages, CSS and JS to a local folder and then host these sites locally. Each time, we then use chromiumâ€™s headless mode to open one site in a tab, and collect the corresponding logs. All the log entries belong to the tab opening CNN.com. We do this for the ten sites and obtain the ground truth. Then, we open the 10 sites in parallel, log entries from different tabs hence interleave with each other. We use ALchemist to partition the application log and the audit log to units and attribute individual events.

Vim. For vim, we place a same set of files in both the "workload" and the "test" folders. We then use a vim script to simulate user behavior, for instance, ":w >>1.out" to write buffer content to a file1.out. We generate a long sequence of random vim script which opens multiple file buffers and reads/writes files in the "workload" folder. Then we execute the commands in the script one by one with more than 30 seconds idle time in between. We take a snapshot before and after executing each command. The differences between two consecutive log snapshots should belong to current unit. Then we rerun the vim script in the "test" folder. Note that we duplicate the files in two folders as file updates may be persistent.

LibreOffice/OpenOffice. The workload setup and experiment of LibreOffice/OpenOffice are similar to that of vim. Specifically, we place a same set of files in both the "workload" and the "test" folders. We use snippets of python code to simulate various kinds of user behaviors such as creating a file and writing to a file, using the APIs provided by LibreOffice/OpenOffice. We then generate a long sequence of random user behaviors based on the primitive snippets. Specifically, it opens files in the "workload" folder and performs various operations on them(e.g. inserting data into a sheet cell). The files are created/accessed in order, with substantial idle time in between (to avoid interleaving of anybackground behaviors). As such, the idle durations serve as the unit boundaries(one unit for each file), which allow us to partition the logs and acquire the ground truth. Then we shuffle the operations in the script so that the operations on all the files interleave. We then execute it in the "test" folder to avoid interference from the ground truth execution.

Foxit. For foxit, we place 10 PDF files to a folder. We then use a command line to open each PDF in a tab, e.g.,"FoxitReader 1.pdf" to open1.pdf, and collect the corresponding logs, which serve as the ground truth. Then we use "FoxitReader 1.pdf 2.pdf ..." to open 10 files simultaneously, causing interleaving.

Transmission. In the workload of transmission, we host 10 large files on a local server and create the corresponding magnet links. We then use a command to add a magnet link(once added, transmission will start to download) and collect the logs. For example, we use "transmission-remote-a link1" to add and download link1. Then, we use "transmission-remote -a link1 link2 ..." to add and download 10 magnet links simultaneously, causing interleaving.
